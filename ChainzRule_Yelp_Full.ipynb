{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nesn0jjqjlyq",
        "outputId": "f781db0e-4a9d-41c2-fdee-0ad446529cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "--- Data Loading ---\n",
            "Loading data from yelp_glove_final_train.npy...\n",
            "Loading data from yelp_glove_final_val (1).npy...\n",
            "Loading data from yelp_glove_final_test (1).npy...\n",
            "Total Train samples: 490,000 | Val: 105,000 | Dim: 308\n",
            "Model initialized with in_features=308\n",
            "Epoch 01/250 | train_loss=0.08527 | val_RMSE=1.3803\n",
            "Epoch 02/250 | train_loss=0.04965 | val_RMSE=1.3447\n",
            "Epoch 03/250 | train_loss=0.04051 | val_RMSE=1.3011\n",
            "Epoch 04/250 | train_loss=0.03421 | val_RMSE=1.2478\n",
            "Epoch 05/250 | train_loss=0.02909 | val_RMSE=1.1856\n",
            "Epoch 06/250 | train_loss=0.02488 | val_RMSE=1.1180\n",
            "Epoch 07/250 | train_loss=0.02146 | val_RMSE=1.0496\n",
            "Epoch 08/250 | train_loss=0.01878 | val_RMSE=0.9837\n",
            "Epoch 09/250 | train_loss=0.01640 | val_RMSE=0.9228\n",
            "Epoch 10/250 | train_loss=0.01452 | val_RMSE=0.8681\n",
            "Epoch 11/250 | train_loss=0.01289 | val_RMSE=0.8202\n",
            "Epoch 12/250 | train_loss=0.01153 | val_RMSE=0.7790\n",
            "Epoch 13/250 | train_loss=0.01042 | val_RMSE=0.7443\n",
            "Epoch 14/250 | train_loss=0.00942 | val_RMSE=0.7153\n",
            "Epoch 15/250 | train_loss=0.00858 | val_RMSE=0.6913\n",
            "Epoch 16/250 | train_loss=0.00784 | val_RMSE=0.6716\n",
            "Epoch 17/250 | train_loss=0.00725 | val_RMSE=0.6555\n",
            "Epoch 18/250 | train_loss=0.00673 | val_RMSE=0.6424\n",
            "Epoch 19/250 | train_loss=0.00632 | val_RMSE=0.6319\n",
            "Epoch 20/250 | train_loss=0.00587 | val_RMSE=0.6234\n",
            "Epoch 21/250 | train_loss=0.00547 | val_RMSE=0.6165\n",
            "Epoch 22/250 | train_loss=0.00517 | val_RMSE=0.6109\n",
            "Epoch 23/250 | train_loss=0.00488 | val_RMSE=0.6063\n",
            "Epoch 24/250 | train_loss=0.00467 | val_RMSE=0.6027\n",
            "Epoch 25/250 | train_loss=0.00438 | val_RMSE=0.5998\n",
            "Epoch 26/250 | train_loss=0.00422 | val_RMSE=0.5973\n",
            "Epoch 27/250 | train_loss=0.00408 | val_RMSE=0.5951\n",
            "Epoch 28/250 | train_loss=0.00392 | val_RMSE=0.5932\n",
            "Epoch 29/250 | train_loss=0.00384 | val_RMSE=0.5915\n",
            "Epoch 30/250 | train_loss=0.00363 | val_RMSE=0.5900\n",
            "Epoch 31/250 | train_loss=0.00344 | val_RMSE=0.5887\n",
            "Epoch 32/250 | train_loss=0.00331 | val_RMSE=0.5877\n",
            "Epoch 33/250 | train_loss=0.00321 | val_RMSE=0.5868\n",
            "Epoch 34/250 | train_loss=0.00310 | val_RMSE=0.5858\n",
            "Epoch 35/250 | train_loss=0.00302 | val_RMSE=0.5849\n",
            "Epoch 36/250 | train_loss=0.00298 | val_RMSE=0.5841\n",
            "Epoch 37/250 | train_loss=0.00288 | val_RMSE=0.5834\n",
            "Epoch 38/250 | train_loss=0.00281 | val_RMSE=0.5827\n",
            "Epoch 39/250 | train_loss=0.00271 | val_RMSE=0.5821\n",
            "Epoch 40/250 | train_loss=0.00260 | val_RMSE=0.5815\n",
            "Epoch 41/250 | train_loss=0.00257 | val_RMSE=0.5809\n",
            "Epoch 42/250 | train_loss=0.00254 | val_RMSE=0.5803\n",
            "Epoch 43/250 | train_loss=0.00248 | val_RMSE=0.5797\n",
            "Epoch 44/250 | train_loss=0.00244 | val_RMSE=0.5792\n",
            "Epoch 45/250 | train_loss=0.00240 | val_RMSE=0.5786\n",
            "Epoch 46/250 | train_loss=0.00232 | val_RMSE=0.5782\n",
            "Epoch 47/250 | train_loss=0.00226 | val_RMSE=0.5777\n",
            "Epoch 48/250 | train_loss=0.00219 | val_RMSE=0.5772\n",
            "Epoch 49/250 | train_loss=0.00216 | val_RMSE=0.5768\n",
            "Epoch 50/250 | train_loss=0.00208 | val_RMSE=0.5764\n",
            "Epoch 51/250 | train_loss=0.00206 | val_RMSE=0.5760\n",
            "Epoch 52/250 | train_loss=0.00202 | val_RMSE=0.5756\n",
            "Epoch 53/250 | train_loss=0.00198 | val_RMSE=0.5750\n",
            "Epoch 54/250 | train_loss=0.00201 | val_RMSE=0.5746\n",
            "Epoch 55/250 | train_loss=0.00201 | val_RMSE=0.5741\n",
            "Epoch 56/250 | train_loss=0.00198 | val_RMSE=0.5737\n",
            "Epoch 57/250 | train_loss=0.00189 | val_RMSE=0.5733\n",
            "Epoch 58/250 | train_loss=0.00184 | val_RMSE=0.5727\n",
            "Epoch 59/250 | train_loss=0.00183 | val_RMSE=0.5723\n",
            "Epoch 60/250 | train_loss=0.00177 | val_RMSE=0.5719\n",
            "Epoch 61/250 | train_loss=0.00171 | val_RMSE=0.5715\n",
            "Epoch 62/250 | train_loss=0.00164 | val_RMSE=0.5712\n",
            "Epoch 63/250 | train_loss=0.00158 | val_RMSE=0.5709\n",
            "Epoch 64/250 | train_loss=0.00157 | val_RMSE=0.5707\n",
            "Epoch 65/250 | train_loss=0.00159 | val_RMSE=0.5704\n",
            "Epoch 66/250 | train_loss=0.00156 | val_RMSE=0.5702\n",
            "Epoch 67/250 | train_loss=0.00155 | val_RMSE=0.5699\n",
            "Epoch 68/250 | train_loss=0.00152 | val_RMSE=0.5697\n",
            "Epoch 69/250 | train_loss=0.00152 | val_RMSE=0.5694\n",
            "Epoch 70/250 | train_loss=0.00149 | val_RMSE=0.5692\n",
            "Epoch 71/250 | train_loss=0.00147 | val_RMSE=0.5689\n",
            "Epoch 72/250 | train_loss=0.00141 | val_RMSE=0.5687\n",
            "Epoch 73/250 | train_loss=0.00139 | val_RMSE=0.5685\n",
            "Epoch 74/250 | train_loss=0.00137 | val_RMSE=0.5682\n",
            "Epoch 75/250 | train_loss=0.00138 | val_RMSE=0.5680\n",
            "Epoch 76/250 | train_loss=0.00132 | val_RMSE=0.5678\n",
            "Epoch 77/250 | train_loss=0.00128 | val_RMSE=0.5676\n",
            "Epoch 78/250 | train_loss=0.00128 | val_RMSE=0.5674\n",
            "Epoch 79/250 | train_loss=0.00124 | val_RMSE=0.5671\n",
            "Epoch 80/250 | train_loss=0.00123 | val_RMSE=0.5668\n",
            "Epoch 81/250 | train_loss=0.00121 | val_RMSE=0.5666\n",
            "Epoch 82/250 | train_loss=0.00120 | val_RMSE=0.5665\n",
            "Epoch 83/250 | train_loss=0.00119 | val_RMSE=0.5663\n",
            "Epoch 84/250 | train_loss=0.00115 | val_RMSE=0.5661\n",
            "Epoch 85/250 | train_loss=0.00112 | val_RMSE=0.5659\n",
            "Epoch 86/250 | train_loss=0.00111 | val_RMSE=0.5658\n",
            "Epoch 87/250 | train_loss=0.00112 | val_RMSE=0.5657\n",
            "Epoch 88/250 | train_loss=0.00111 | val_RMSE=0.5655\n",
            "Epoch 89/250 | train_loss=0.00109 | val_RMSE=0.5654\n",
            "Epoch 90/250 | train_loss=0.00105 | val_RMSE=0.5653\n",
            "Epoch 91/250 | train_loss=0.00101 | val_RMSE=0.5652\n",
            "Epoch 92/250 | train_loss=0.00098 | val_RMSE=0.5650\n",
            "Epoch 93/250 | train_loss=0.00096 | val_RMSE=0.5648\n",
            "Epoch 94/250 | train_loss=0.00095 | val_RMSE=0.5647\n",
            "Epoch 95/250 | train_loss=0.00096 | val_RMSE=0.5645\n",
            "Epoch 96/250 | train_loss=0.00095 | val_RMSE=0.5645\n",
            "Epoch 97/250 | train_loss=0.00095 | val_RMSE=0.5644\n",
            "Epoch 98/250 | train_loss=0.00092 | val_RMSE=0.5643\n",
            "Epoch 99/250 | train_loss=0.00091 | val_RMSE=0.5643\n",
            "Epoch 100/250 | train_loss=0.00090 | val_RMSE=0.5642\n",
            "Epoch 101/250 | train_loss=0.00087 | val_RMSE=0.5641\n",
            "Epoch 102/250 | train_loss=0.00086 | val_RMSE=0.5640\n",
            "Epoch 103/250 | train_loss=0.00083 | val_RMSE=0.5640\n",
            "Epoch 104/250 | train_loss=0.00081 | val_RMSE=0.5639\n",
            "Epoch 105/250 | train_loss=0.00080 | val_RMSE=0.5638\n",
            "Epoch 106/250 | train_loss=0.00078 | val_RMSE=0.5638\n",
            "Epoch 107/250 | train_loss=0.00078 | val_RMSE=0.5637\n",
            "Epoch 108/250 | train_loss=0.00077 | val_RMSE=0.5637\n",
            "Epoch 109/250 | train_loss=0.00076 | val_RMSE=0.5637\n",
            "Epoch 110/250 | train_loss=0.00074 | val_RMSE=0.5636\n",
            "Epoch 111/250 | train_loss=0.00072 | val_RMSE=0.5636\n",
            "Epoch 112/250 | train_loss=0.00072 | val_RMSE=0.5636\n",
            "Epoch 113/250 | train_loss=0.00071 | val_RMSE=0.5636\n",
            "Epoch 114/250 | train_loss=0.00070 | val_RMSE=0.5635\n",
            "Epoch 115/250 | train_loss=0.00069 | val_RMSE=0.5635\n",
            "Epoch 116/250 | train_loss=0.00069 | val_RMSE=0.5635\n",
            "Epoch 117/250 | train_loss=0.00067 | val_RMSE=0.5635\n",
            "Epoch 118/250 | train_loss=0.00065 | val_RMSE=0.5635\n",
            "Epoch 119/250 | train_loss=0.00063 | val_RMSE=0.5635\n",
            "Epoch 120/250 | train_loss=0.00062 | val_RMSE=0.5636\n",
            "Epoch 121/250 | train_loss=0.00062 | val_RMSE=0.5636\n",
            "Epoch 122/250 | train_loss=0.00062 | val_RMSE=0.5637\n",
            "Epoch 123/250 | train_loss=0.00060 | val_RMSE=0.5637\n",
            "Epoch 124/250 | train_loss=0.00060 | val_RMSE=0.5637\n",
            "Epoch 125/250 | train_loss=0.00058 | val_RMSE=0.5638\n",
            "Epoch 126/250 | train_loss=0.00057 | val_RMSE=0.5638\n",
            "Epoch 127/250 | train_loss=0.00056 | val_RMSE=0.5638\n",
            "Epoch 128/250 | train_loss=0.00054 | val_RMSE=0.5638\n",
            "Epoch 129/250 | train_loss=0.00054 | val_RMSE=0.5639\n",
            "Epoch 130/250 | train_loss=0.00052 | val_RMSE=0.5639\n",
            "Epoch 131/250 | train_loss=0.00053 | val_RMSE=0.5640\n",
            "Epoch 132/250 | train_loss=0.00052 | val_RMSE=0.5640\n",
            "Epoch 133/250 | train_loss=0.00051 | val_RMSE=0.5641\n",
            "Epoch 134/250 | train_loss=0.00050 | val_RMSE=0.5641\n",
            "Epoch 135/250 | train_loss=0.00049 | val_RMSE=0.5641\n",
            "Epoch 136/250 | train_loss=0.00049 | val_RMSE=0.5642\n",
            "Epoch 137/250 | train_loss=0.00047 | val_RMSE=0.5642\n",
            "Epoch 138/250 | train_loss=0.00046 | val_RMSE=0.5643\n",
            "Epoch 139/250 | train_loss=0.00045 | val_RMSE=0.5644\n",
            "Epoch 140/250 | train_loss=0.00045 | val_RMSE=0.5644\n",
            "Epoch 141/250 | train_loss=0.00044 | val_RMSE=0.5645\n",
            "Epoch 142/250 | train_loss=0.00044 | val_RMSE=0.5646\n",
            "Epoch 143/250 | train_loss=0.00043 | val_RMSE=0.5647\n",
            "Epoch 144/250 | train_loss=0.00042 | val_RMSE=0.5647\n",
            "Epoch 145/250 | train_loss=0.00042 | val_RMSE=0.5648\n",
            "Epoch 146/250 | train_loss=0.00041 | val_RMSE=0.5649\n",
            "Epoch 147/250 | train_loss=0.00040 | val_RMSE=0.5649\n",
            "Epoch 148/250 | train_loss=0.00039 | val_RMSE=0.5650\n",
            "Epoch 149/250 | train_loss=0.00039 | val_RMSE=0.5651\n",
            "Epoch 150/250 | train_loss=0.00039 | val_RMSE=0.5651\n",
            "Epoch 151/250 | train_loss=0.00038 | val_RMSE=0.5652\n",
            "Epoch 152/250 | train_loss=0.00037 | val_RMSE=0.5654\n",
            "Epoch 153/250 | train_loss=0.00036 | val_RMSE=0.5655\n",
            "Epoch 154/250 | train_loss=0.00036 | val_RMSE=0.5655\n",
            "Epoch 155/250 | train_loss=0.00035 | val_RMSE=0.5656\n",
            "Epoch 156/250 | train_loss=0.00034 | val_RMSE=0.5657\n",
            "Epoch 157/250 | train_loss=0.00034 | val_RMSE=0.5658\n",
            "Early stopping.\n",
            "\n",
            "=== Training Complete ===\n",
            "\n",
            "== Tuned thresholds (VAL, optimize QWK) == [0.2, 1.5, 2.5, 3.8] | val_score=0.9130\n",
            "Saved tuned thresholds to rating_thresholds.json\n",
            "\n",
            "=== Test Metrics (tuned thresholds) ===\n",
            "RMSE: 0.5669 | MAE: 0.2440 | Acc(round): 0.8300 | QWK: 0.9126\n",
            "Total train time: 6340.54s\n"
          ]
        }
      ],
      "source": [
        "# train_chainrule_head.py\n",
        "# Train ChainRule head on frozen Hierarchical embeddings (300D), using combined feature+label NPY files\n",
        "# assuming files are in the CURRENT WORKING DIRECTORY (e.g., where this script is run from).\n",
        "import os, math, time, random\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.swa_utils import AveragedModel, get_ema_avg_fn\n",
        "import json\n",
        "\n",
        "# ============ Config ============\n",
        "# --- Data Paths: These files are assumed to be in the current working directory. ---\n",
        "FEATURE_TRAIN    = \"yelp_glove_final_train.npy\"\n",
        "FEATURE_VAL      = \"yelp_glove_final_val (1).npy\"\n",
        "FEATURE_TEST     = \"yelp_glove_final_test (1).npy\"\n",
        "# NOTE: The last column of these files is assumed to contain the rating score (0-4).\n",
        "\n",
        "TARGET_MIN, TARGET_MAX = 0.0, 4.0\n",
        "\n",
        "# --- Hyperparameters (7400 Hidden Features, Aggressively Balanced) ---\n",
        "BATCH_TRAIN = 4096      # Increased for gradient stability (necessary with very low LR)\n",
        "BATCH_TEST  = 6144\n",
        "EPOCHS      = 250     # Drastically increased for extremely slow convergence\n",
        "LR          = 5e-4      # Severely reduced (0.0005) for high-capacity stability\n",
        "WDECAY      = 1.5e-3    # CRITICAL: Max L2 regularization to fight catastrophic overfitting\n",
        "DREG        = 8e-5      # CRITICAL: Max DREG to enforce function smoothness\n",
        "PATIENCE    = 40      # Highly increased to allow time for slow convergence\n",
        "USE_AMP     = True\n",
        "hidden_features = 10000 # Increased Capacity\n",
        "num_layers  = 2\n",
        "degrees     = 3\n",
        "dropout     = 0.0       # Dropout remains off (relying completely on L2 and DREG)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if DEVICE.type == \"cuda\":\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    try:\n",
        "        torch.set_float32_matmul_precision(\"high\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "SEED = 1337\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# ============ Metrics ============\n",
        "def rmse(y_true, y_pred):\n",
        "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return float(np.mean(np.abs(y_true - y_pred)))\n",
        "\n",
        "def qwk(y_true, y_pred, min_rating=0, max_rating=4):\n",
        "    y_true = np.asarray(y_true, dtype=int)\n",
        "    y_pred = np.asarray(y_pred, dtype=int)\n",
        "    M = max_rating - min_rating + 1\n",
        "    O = np.zeros((M, M), dtype=np.float64)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        if min_rating <= t <= max_rating and min_rating <= p <= max_rating:\n",
        "            O[t - min_rating, p - min_rating] += 1.0\n",
        "    act_hist = O.sum(axis=1)\n",
        "    pred_hist = O.sum(axis=0)\n",
        "    E = np.outer(act_hist, pred_hist) / max(1.0, O.sum())\n",
        "    W = np.zeros((M, M))\n",
        "    for i in range(M):\n",
        "        for j in range(M):\n",
        "            W[i, j] = ((i - j) ** 2) / ((M - 1) ** 2)\n",
        "    num = (W * O).sum()\n",
        "    den = (W * E).sum() if (W * E).sum() != 0 else 1.0\n",
        "    return 1.0 - num / den\n",
        "\n",
        "def round_clip(x):\n",
        "    return np.clip(np.rint(x), TARGET_MIN, TARGET_MAX).astype(int)\n",
        "\n",
        "def apply_thresholds(p_cont, ts):\n",
        "    \"\"\"ts = [t1,t2,t3,t4] on 0..4; returns integer 0..4 via np.digitize.\"\"\"\n",
        "    ts = np.asarray(ts, dtype=np.float32)\n",
        "    return np.digitize(p_cont, ts).astype(int)\n",
        "\n",
        "def greedy_search_thresholds(y_true_int, p_cont, metric=\"qwk\",\n",
        "                             start_ts=(0.5,1.5,2.5,3.5),\n",
        "                             sweeps=3, step=0.10, margin=0.40):\n",
        "    \"\"\"Coordinate-descent tuner for 4 thresholds on 0..4.\"\"\"\n",
        "    ts = np.array(start_ts, dtype=np.float32)\n",
        "\n",
        "    def score_with(ts_local):\n",
        "        pr = apply_thresholds(p_cont, ts_local)\n",
        "        if metric == \"acc\":\n",
        "            return (pr == y_true_int).mean()\n",
        "        else:\n",
        "            return qwk(y_true_int, pr)\n",
        "\n",
        "    best_score = score_with(ts)\n",
        "    for _ in range(sweeps):\n",
        "        for i in range(4):\n",
        "            low = (ts[i-1] + 1e-3) if i > 0 else 0.0\n",
        "            high = (ts[i+1] - 1e-3) if i < 3 else 4.0\n",
        "            cand_grid = np.arange(max(low, ts[i]-margin),\n",
        "                                  min(high, ts[i]+margin)+1e-9, step, dtype=np.float32)\n",
        "            local_best = ts[i]; local_best_score = best_score\n",
        "            for c in cand_grid:\n",
        "                ts_try = ts.copy(); ts_try[i] = c\n",
        "                s = score_with(ts_try)\n",
        "                if s > local_best_score:\n",
        "                    local_best_score = s\n",
        "                    local_best = c\n",
        "            ts[i] = local_best\n",
        "            best_score = local_best_score\n",
        "    return ts.tolist(), float(best_score)\n",
        "\n",
        "@torch.no_grad()\n",
        "def _collect_preds_cont(model, loader):\n",
        "    \"\"\"Return (y_true_int, y_pred_cont_0to4) from a loader (uses EMA if present).\"\"\"\n",
        "    eval_model = model.module if isinstance(model, AveragedModel) else model\n",
        "    eval_model.eval()\n",
        "    ys_true, ys_pred = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE, non_blocking=True)\n",
        "        if xb.ndim != 2 or xb.shape[-1] != in_dim:\n",
        "            xb = xb.view(-1, in_dim)\n",
        "        out, _ = eval_model(xb)\n",
        "        yhat_s = torch.sigmoid(out)\n",
        "        yhat   = TARGET_MIN + (TARGET_MAX - TARGET_MIN) * yhat_s\n",
        "        ys_true.append(yb.numpy())\n",
        "        ys_pred.append(yhat.squeeze(-1).cpu().numpy())\n",
        "    y = np.concatenate(ys_true).astype(int)\n",
        "    p = np.concatenate(ys_pred).astype(np.float32)\n",
        "    return y, p\n",
        "\n",
        "# ============ ChainRule Model ============\n",
        "class PolyLayerStable(nn.Module):\n",
        "    def __init__(self, features: int, degree: int):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "        self.degree = degree\n",
        "        self.raw_coeffs = nn.Parameter(torch.randn(features, degree + 1) * 0.05)\n",
        "        self.gamma = nn.Parameter(torch.zeros(features))\n",
        "        self.scale = 0.5\n",
        "    def forward(self, h, dh):\n",
        "        coeffs = self.scale * torch.tanh(self.raw_coeffs)\n",
        "        # polynomial forward\n",
        "        powers = [torch.ones_like(h)]\n",
        "        for _ in range(1, self.degree + 1):\n",
        "            powers.append(powers[-1] * h)\n",
        "        H = torch.stack(powers, dim=-1)         # (B,F,deg+1)\n",
        "        y = torch.sum(H * coeffs, dim=-1)       # (B,F)\n",
        "        # derivative part\n",
        "        if self.degree >= 1:\n",
        "            ar = torch.arange(1, self.degree + 1, device=h.device, dtype=h.dtype)\n",
        "            deriv_coeffs = coeffs[:, 1:] * ar    # (F,deg)\n",
        "            dlocal = torch.sum(H[..., :-1] * deriv_coeffs, dim=-1) # (B,F)\n",
        "        else:\n",
        "            dlocal = torch.zeros_like(h)\n",
        "        y = y + 0.1 * self.gamma * dh\n",
        "        dh_out = dlocal * dh\n",
        "        return y, dh_out\n",
        "\n",
        "class ChainRulePolyNetStable(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=256, num_layers=2, degree=3):\n",
        "        super().__init__()\n",
        "        self.in_map = nn.Linear(in_features, hidden_features)\n",
        "        self.in_norm = nn.LayerNorm(hidden_features)         # NEW\n",
        "        self.in_drop = nn.Dropout(p=dropout)                     # NEW\n",
        "        self.layers = nn.ModuleList([PolyLayerStable(hidden_features, degree) for _ in range(num_layers)])\n",
        "        self.out_map = nn.Linear(hidden_features, 1)\n",
        "    def forward(self, x):\n",
        "        h = self.in_map(x)\n",
        "        h = self.in_drop(self.in_norm(torch.nn.functional.gelu(h)))  # NEW\n",
        "        dh = torch.ones_like(h)\n",
        "        reg = 0.0\n",
        "        for layer in self.layers:\n",
        "            h, dh = layer(h, dh)\n",
        "            reg = reg + torch.mean(dh ** 2)\n",
        "        y = self.out_map(h) # (B,1)\n",
        "        return y, reg / max(1, len(self.layers))\n",
        "\n",
        "# ============ Datasets (Combined Feature/Label Logic) ============\n",
        "\n",
        "def _safe_load_npy(path: str):\n",
        "    \"\"\"\n",
        "    Try memory-mapped load first; if the file was saved/truncated oddly,\n",
        "    fall back to a normal load (no mmap). Raises a clear error if both fail.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return np.load(path, mmap_mode=\"r\")\n",
        "    except Exception as e_mmap:\n",
        "        print(f\"⚠️ mmap load failed for '{path}': {e_mmap}\\n   → Retrying without mmap...\")\n",
        "        try:\n",
        "            return np.load(path)  # no mmap\n",
        "        except Exception as e_plain:\n",
        "            raise RuntimeError(\n",
        "                f\"Failed to load '{path}' even without mmap. \"\n",
        "                f\"The file may be truncated or corrupted. Original error: {e_plain}\"\n",
        "            )\n",
        "\n",
        "class CombinedNumpyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for pre-split NumPy files where the final column is the label.\n",
        "    Accepts either a proper 2D numeric array (N, D+1) or a flat 1D numeric array\n",
        "    that can be reshaped into (N, D+1) when divisible by a plausible column count.\n",
        "    \"\"\"\n",
        "    def __init__(self, full_path: str, prefer_cols: int | None = None):\n",
        "        print(f\"Loading data from {full_path}...\")\n",
        "        if not os.path.exists(full_path):\n",
        "            raise FileNotFoundError(f\"File not found: {full_path}\")\n",
        "\n",
        "        data = _safe_load_npy(full_path)\n",
        "\n",
        "        if data.dtype == np.object_:\n",
        "            raise ValueError(\n",
        "                f\"{full_path} is an object array (likely pickled). \"\n",
        "                f\"Re-save as numeric (e.g., float32) with shape (N, D+1).\"\n",
        "            )\n",
        "\n",
        "        # Case 1: Already 2D\n",
        "        if data.ndim == 2:\n",
        "            self.features = np.array(data[:, :-1], dtype=np.float32, copy=True)  # was: np.asarray(...)\n",
        "            self.labels   = np.array(data[:,  -1], dtype=np.float32, copy=True).reshape(-1)\n",
        "            self.dim = self.features.shape[1]\n",
        "            return\n",
        "\n",
        "        # Case 2: Flat 1D → try to infer and reshape\n",
        "        if data.ndim == 1:\n",
        "            total = data.size\n",
        "            candidates = []\n",
        "\n",
        "            # Prefer a known columns count if provided (e.g., 300D + 1 label = 301)\n",
        "            if prefer_cols is not None and total % prefer_cols == 0:\n",
        "                candidates.append(prefer_cols)\n",
        "\n",
        "            # Otherwise search a reasonable range of divisors\n",
        "            if not candidates:\n",
        "                for c in range(32, 4097):\n",
        "                    if total % c == 0:\n",
        "                        candidates.append(c)\n",
        "\n",
        "            if not candidates:\n",
        "                raise ValueError(\n",
        "                    f\"{full_path}: flat size {total:,} has no reasonable divisors in [32, 4096]; \"\n",
        "                    f\"cannot infer (features+label) column count.\"\n",
        "                )\n",
        "\n",
        "            # Pick the candidate closest to common shapes like 301/309\n",
        "            candidates.sort(key=lambda c: min(abs(c - 301), abs(c - 309)))\n",
        "            cols = candidates[0]\n",
        "            n = total // cols\n",
        "            print(f\"ℹ️  Inferred shape for {full_path}: ({n:,}, {cols}) → features={cols-1}, label=1.\")\n",
        "\n",
        "            data2d = np.array(data, dtype=np.float32, copy=True).reshape(n, cols)\n",
        "            self.features = data2d[:, :-1]\n",
        "            self.labels   = data2d[:,  -1].reshape(-1)\n",
        "            self.dim = self.features.shape[1]\n",
        "            return\n",
        "\n",
        "        raise ValueError(f\"{full_path} has ndim={data.ndim}; expected 1D (flat) or 2D numeric array.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.from_numpy(self.features[idx])\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "def build_loaders_from_files():\n",
        "    \"\"\"Loads pre-split data from combined NPY files and creates DataLoaders.\"\"\"\n",
        "    print(f\"--- Data Loading ---\")\n",
        "\n",
        "    # If you know your exact columns (e.g., 300D + 1 label = 301), set prefer_cols=301.\n",
        "    # Otherwise leave None to auto-infer for each file.\n",
        "    prefer_cols = None  # e.g., set to 301 if you want to enforce 300D+label\n",
        "\n",
        "    try:\n",
        "        train_dataset = CombinedNumpyDataset(FEATURE_TRAIN, prefer_cols=prefer_cols)\n",
        "        val_dataset   = CombinedNumpyDataset(FEATURE_VAL,   prefer_cols=prefer_cols)\n",
        "\n",
        "        if os.path.exists(FEATURE_TEST):\n",
        "            test_dataset = CombinedNumpyDataset(FEATURE_TEST, prefer_cols=prefer_cols)\n",
        "        else:\n",
        "            test_dataset = None\n",
        "            print(f\"Warning: Test file {FEATURE_TEST} not found. Test set will be skipped.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            f\"Error loading combined NPY files. Ensure files are numeric (features + label) and not truncated. \"\n",
        "            f\"Error: {e}\"\n",
        "        )\n",
        "\n",
        "    in_dim = train_dataset.dim\n",
        "    if val_dataset.dim != in_dim or (test_dataset and test_dataset.dim != in_dim):\n",
        "        raise ValueError(\n",
        "            f\"Embedding dimensions must match across splits: \"\n",
        "            f\"train={in_dim}, val={val_dataset.dim}, \"\n",
        "            f\"test={(test_dataset.dim if test_dataset else '—')}.\"\n",
        "        )\n",
        "\n",
        "    print(f\"Total Train samples: {len(train_dataset):,} | Val: {len(val_dataset):,} | Dim: {in_dim}\")\n",
        "\n",
        "    pin = (DEVICE.type == \"cuda\")\n",
        "    # cap at 2 when on this runtime\n",
        "    n_workers = 2 if pin else 0\n",
        "    persistent = (n_workers > 0)\n",
        "\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=BATCH_TRAIN, shuffle=True,\n",
        "        pin_memory=pin, num_workers=n_workers, persistent_workers=persistent\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=BATCH_TEST, shuffle=False,\n",
        "        pin_memory=pin, num_workers=n_workers, persistent_workers=persistent\n",
        "    )\n",
        "    test_loader = None\n",
        "    if test_dataset:\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset, batch_size=BATCH_TEST, shuffle=False,\n",
        "            pin_memory=pin, num_workers=n_workers, persistent_workers=persistent\n",
        "        )\n",
        "\n",
        "    return train_loader, val_loader, test_loader, in_dim\n",
        "\n",
        "# ============ Training / Eval ============\n",
        "def train_loop(model, train_loader, val_loader, epochs=EPOCHS, lr=LR, wdecay=WDECAY, dreg=DREG, use_amp=USE_AMP):\n",
        "    model = model.to(DEVICE)\n",
        "    # CHANGED: modern GradScaler API\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(use_amp and DEVICE.type == \"cuda\"))  # NEW\n",
        "\n",
        "    # CHANGED: fused AdamW when available\n",
        "    opt = AdamW(model.parameters(), lr=lr, weight_decay=wdecay, fused=torch.cuda.is_available())  # NEW\n",
        "\n",
        "    # NEW: warmup + cosine schedule\n",
        "    total_steps = max(1, epochs * len(train_loader))\n",
        "    warmup_steps = max(10, len(train_loader))\n",
        "    def lr_lambda(step):\n",
        "        if step < warmup_steps:\n",
        "            return float(step + 1) / warmup_steps\n",
        "        t = (step - warmup_steps) / max(1, (total_steps - warmup_steps))\n",
        "        return 0.01 + 0.99 * 0.5 * (1 + math.cos(math.pi * t))\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)  # NEW\n",
        "\n",
        "    # NEW: EMA tracking\n",
        "    ema = AveragedModel(model, avg_fn=get_ema_avg_fn(0.999))\n",
        "\n",
        "    best_val = math.inf\n",
        "    best = None\n",
        "    best_ema = None  # NEW\n",
        "    no_improve = 0\n",
        "    global in_dim  # uses the in_dim discovered in main()\n",
        "\n",
        "    step_idx = 0  # NEW\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        tot, n = 0.0, 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb = xb.to(DEVICE, non_blocking=True)\n",
        "\n",
        "            # Ensure (B, in_dim)\n",
        "            if xb.ndim != 2 or xb.shape[-1] != in_dim:\n",
        "                xb = xb.view(-1, in_dim)\n",
        "\n",
        "            # scale labels to [0,1]\n",
        "            ys = ((yb.to(DEVICE, non_blocking=True) - TARGET_MIN) / (TARGET_MAX - TARGET_MIN)).unsqueeze(-1)\n",
        "\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            if use_amp and DEVICE.type == \"cuda\":\n",
        "                # CHANGED: modern autocast\n",
        "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                    yhat_s, reg = model(xb)\n",
        "                    yhat_s = torch.sigmoid(yhat_s)\n",
        "                    reg = torch.clamp(reg, max=10.0)  # NEW: cap reg\n",
        "                    loss = nn.functional.mse_loss(yhat_s, ys) + dreg * reg\n",
        "                scaler.scale(loss).backward()\n",
        "                # NEW: clip grads in AMP path (after unscale)\n",
        "                scaler.unscale_(opt)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "                scaler.step(opt); scaler.update()\n",
        "            else:\n",
        "                yhat_s, reg = model(xb)\n",
        "                yhat_s = torch.sigmoid(yhat_s)\n",
        "                reg = torch.clamp(reg, max=10.0)  # NEW: cap reg\n",
        "                loss = nn.functional.mse_loss(yhat_s, ys) + dreg * reg\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)  # CHANGED: 0.5\n",
        "                opt.step()\n",
        "\n",
        "            # NEW: EMA + scheduler step\n",
        "            ema.update_parameters(model)\n",
        "            scheduler.step()\n",
        "            step_idx += 1\n",
        "\n",
        "            bs = xb.size(0)\n",
        "            tot += loss.item() * bs\n",
        "            n += bs\n",
        "\n",
        "        val_rmse = eval_loop(ema, val_loader)[\"rmse\"]  # CHANGED: eval EMA params\n",
        "        print(f\"Epoch {ep:02d}/{epochs} | train_loss={tot/max(1,n):.5f} | val_RMSE={val_rmse:.4f}\")\n",
        "\n",
        "        if val_rmse + 1e-6 < best_val:\n",
        "            best_val = val_rmse\n",
        "            best = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "            best_ema = {k: v.cpu() for k, v in ema.module.state_dict().items()}  # NEW\n",
        "            no_improve = 0\n",
        "        else:\n",
        "            no_improve += 1\n",
        "            if no_improve >= PATIENCE:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    if best is not None:\n",
        "        model.load_state_dict(best)\n",
        "        if best_ema is not None:\n",
        "            ema.module.load_state_dict(best_ema)  # NEW\n",
        "\n",
        "    # Return the EMA-smoothed model for downstream eval\n",
        "    return ema  # CHANGED\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_loop(model, loader, thresholds=None):\n",
        "    eval_model = model.module if isinstance(model, AveragedModel) else model\n",
        "    eval_model.eval()\n",
        "    ys_true, ys_pred = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE, non_blocking=True)\n",
        "        if xb.ndim != 2 or xb.shape[-1] != in_dim:\n",
        "            xb = xb.view(-1, in_dim)\n",
        "        out, _ = eval_model(xb)\n",
        "        yhat_s = torch.sigmoid(out)\n",
        "        yhat = TARGET_MIN + (TARGET_MAX - TARGET_MIN) * yhat_s\n",
        "        ys_true.append(yb.numpy())\n",
        "        ys_pred.append(yhat.squeeze(-1).cpu().numpy())\n",
        "\n",
        "    y = np.concatenate(ys_true)\n",
        "    p = np.concatenate(ys_pred)\n",
        "\n",
        "    r = rmse(y, p)\n",
        "    m = mae(y, p)\n",
        "    if thresholds is None:\n",
        "        pr = round_clip(p)                     # old midpoint rounding\n",
        "    else:\n",
        "        pr = apply_thresholds(p, thresholds)   # tuned thresholds\n",
        "    acc = float(np.mean(pr == y.astype(int)))\n",
        "    kappa = qwk(y.astype(int), pr)\n",
        "    return {\"rmse\": r, \"mae\": m, \"acc_round\": acc, \"qwk\": kappa}\n",
        "\n",
        "\n",
        "# ============ Main ============\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Device: {DEVICE.type}\")\n",
        "\n",
        "    # --- Initial File Check ---\n",
        "    if not os.path.exists(FEATURE_TRAIN):\n",
        "        raise FileNotFoundError(f\"Training file '{FEATURE_TRAIN}' not found. Ensure it is in the current working directory.\")\n",
        "    if not os.path.exists(FEATURE_VAL):\n",
        "        raise FileNotFoundError(f\"Validation file '{FEATURE_VAL}' not found. Ensure it is in the current working directory.\")\n",
        "\n",
        "    train_loader, val_loader, test_loader, in_dim = build_loaders_from_files()\n",
        "\n",
        "    # Initialize model using the dynamically determined input dimension\n",
        "    model = ChainRulePolyNetStable(in_features=in_dim, hidden_features=hidden_features, num_layers=num_layers, degree=degrees)\n",
        "    print(f\"Model initialized with in_features={in_dim}\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model = train_loop(model, train_loader, val_loader)\n",
        "    dur = time.time() - t0\n",
        "\n",
        "    print(\"\\n=== Training Complete ===\")\n",
        "    # --- Learn tuned thresholds on the validation set (optimize QWK by default) ---\n",
        "    y_val_int, p_val_cont = _collect_preds_cont(model, val_loader)\n",
        "    BEST_THRESHOLDS, BEST_VAL_SCORE = greedy_search_thresholds(\n",
        "        y_val_int, p_val_cont, metric=\"qwk\", start_ts=(0.5,1.5,2.5,3.5),\n",
        "        sweeps=3, step=0.10, margin=0.40\n",
        "    )\n",
        "    print(f\"\\n== Tuned thresholds (VAL, optimize QWK) == { [round(t,3) for t in BEST_THRESHOLDS] }\"\n",
        "          f\" | val_score={BEST_VAL_SCORE:.4f}\")\n",
        "\n",
        "    # (Optional) persist thresholds\n",
        "    with open(\"rating_thresholds.json\", \"w\") as f:\n",
        "        json.dump({\"thresholds\": BEST_THRESHOLDS}, f)\n",
        "    print(\"Saved tuned thresholds to rating_thresholds.json\")\n",
        "\n",
        "\n",
        "    if test_loader:\n",
        "        metrics = eval_loop(model, test_loader, thresholds=BEST_THRESHOLDS)  # <- use tuned bins\n",
        "        print(\"\\n=== Test Metrics (tuned thresholds) ===\")\n",
        "        print(f\"RMSE: {metrics['rmse']:.4f} | MAE: {metrics['mae']:.4f} | \"\n",
        "              f\"Acc(round): {metrics['acc_round']:.4f} | QWK: {metrics['qwk']:.4f}\")\n",
        "    else:\n",
        "        print(\"Test metrics skipped because the test data file was not found.\")\n",
        "\n",
        "\n",
        "    print(f\"Total train time: {dur:.2f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Parameter accounting ----\n",
        "def count_params(model):\n",
        "    # Access the underlying model if it's an AveragedModel\n",
        "    if isinstance(model, AveragedModel):\n",
        "        model = model.module\n",
        "\n",
        "    total = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    # Per-submodule tallies\n",
        "    sub = {}\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        top = name.split('.')[0]  # e.g., 'in_map', 'in_norm', 'layers', 'out_map'\n",
        "        sub[top] = sub.get(top, 0) + p.numel()\n",
        "\n",
        "    # Poly-layer \"embedded\" params = all raw_coeffs + gamma across layers\n",
        "    poly_embedded = 0\n",
        "    # Check if the model has layers before iterating\n",
        "    if hasattr(model, 'layers'):\n",
        "        for l in model.layers:\n",
        "            # Check if the layer has raw_coeffs and gamma before accessing\n",
        "            if hasattr(l, 'raw_coeffs'):\n",
        "                 poly_embedded += l.raw_coeffs.numel()\n",
        "            if hasattr(l, 'gamma'):\n",
        "                 poly_embedded += l.gamma.numel()\n",
        "\n",
        "\n",
        "    return total, sub, poly_embedded\n",
        "\n",
        "total, sub_breakdown, poly_embedded = count_params(model)\n",
        "\n",
        "print(\"\\n=== Parameter Counts ===\")\n",
        "print(f\"Total trainable params: {total:,}\")\n",
        "for k in sorted(sub_breakdown.keys()):\n",
        "    print(f\"  {k:8s}: {sub_breakdown[k]:,}\")\n",
        "print(f\"Embedded params (poly raw_coeffs + gamma): {poly_embedded:,}\")\n",
        "print(\"External frozen embeddings in .npy (not part of model): 0 trainable params\")\n",
        "print(f\"Your KPI is {metrics['acc_round']*100/np.log10(total)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjbczkN96OOl",
        "outputId": "9c0fd832-6f93-4f6b-81de-7cf356e3d6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Parameter Counts ===\n",
            "Total trainable params: 3,220,001\n",
            "  in_map  : 3,090,000\n",
            "  in_norm : 20,000\n",
            "  layers  : 100,000\n",
            "  out_map : 10,001\n",
            "Embedded params (poly raw_coeffs + gamma): 100,000\n",
            "External frozen embeddings in .npy (not part of model): 0 trainable params\n",
            "Your KPI is 12.753230924655274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import json\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "# Assuming the necessary utility functions like apply_thresholds and\n",
        "# _collect_preds_cont, along with global variables (model, test_loader,\n",
        "# TARGET_MIN, TARGET_MAX) are defined from the main script execution.\n",
        "\n",
        "# Re-defining necessary utility from user's script for robust execution:\n",
        "def apply_thresholds(p_cont, ts):\n",
        "    \"\"\"ts = [t1,t2,t3,t4] on 0..4; returns integer 0..4 via np.digitize.\"\"\"\n",
        "    ts = np.asarray(ts, dtype=np.float32)\n",
        "    return np.digitize(p_cont, ts).astype(int)\n",
        "\n",
        "# ============ FINAL EVALUATION CELL ============\n",
        "print(\"\\n=== Calculating F1, Precision, and Recall on Test Set ===\")\n",
        "\n",
        "# 1. Load Tuned Thresholds (saved during the main script's final steps)\n",
        "try:\n",
        "    with open(\"rating_thresholds.json\", \"r\") as f:\n",
        "        threshold_data = json.load(f)\n",
        "        BEST_THRESHOLDS = threshold_data[\"thresholds\"]\n",
        "    print(f\"Loaded optimal thresholds: {[round(t, 3) for t in BEST_THRESHOLDS]}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'rating_thresholds.json' not found. Ensure the main training script ran successfully and saved the thresholds.\")\n",
        "    BEST_THRESHOLDS = None\n",
        "except Exception as e:\n",
        "    print(f\"Error loading thresholds: {e}\")\n",
        "    BEST_THRESHOLDS = None\n",
        "\n",
        "if BEST_THRESHOLDS and 'test_loader' in locals():\n",
        "    # 2. Collect True Labels and Continuous Predictions\n",
        "    # NOTE: This line requires the _collect_preds_cont function and the EMA model object ('model')\n",
        "    y_true_int, p_cont = _collect_preds_cont(model, test_loader)\n",
        "\n",
        "    # 3. Apply Tuned Thresholds to get Discrete Predictions (0, 1, 2, 3, 4)\n",
        "    y_pred_int = apply_thresholds(p_cont, BEST_THRESHOLDS)\n",
        "\n",
        "    # 4. Calculate Classification Metrics (Multi-class 0-4)\n",
        "    # Using 'weighted' average accounts for class imbalance\n",
        "    f1 = f1_score(y_true_int, y_pred_int, average='weighted')\n",
        "    precision = precision_score(y_true_int, y_pred_int, average='weighted')\n",
        "    recall = recall_score(y_true_int, y_pred_int, average='weighted')\n",
        "\n",
        "    print(\"\\n--- Weighted Classification Metrics ---\")\n",
        "    print(f\"Test Precision (Weighted): {precision:.4f}\")\n",
        "    print(f\"Test Recall (Weighted):    {recall:.4f}\")\n",
        "    print(f\"Test F1-Score (Weighted):  {f1:.4f}\")\n",
        "\n",
        "    # Optional: Detailed report for each class (0, 1, 2, 3, 4)\n",
        "    print(\"\\nDetailed Multi-Class Classification Report:\")\n",
        "    # Assuming TARGET_MIN and TARGET_MAX are available globally\n",
        "    target_names = [str(i) for i in range(int(TARGET_MIN), int(TARGET_MAX) + 1)]\n",
        "    print(classification_report(y_true_int, y_pred_int, target_names=target_names))\n",
        "\n",
        "else:\n",
        "    print(\"Skipping F1/P/R calculation: Thresholds file or Test Loader not available.\")"
      ],
      "metadata": {
        "id": "4a6kfJRYIhBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b28cc85-bc18-4beb-c0ae-0d2b8e6b2818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Calculating F1, Precision, and Recall on Test Set ===\n",
            "Loaded optimal thresholds: [0.2, 1.5, 2.5, 3.8]\n",
            "\n",
            "--- Weighted Classification Metrics ---\n",
            "Test Precision (Weighted): 0.8365\n",
            "Test Recall (Weighted):    0.8300\n",
            "Test F1-Score (Weighted):  0.8314\n",
            "\n",
            "Detailed Multi-Class Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.88     21834\n",
            "           1       0.78      0.84      0.81     21624\n",
            "           2       0.78      0.83      0.80     22251\n",
            "           3       0.78      0.84      0.81     21093\n",
            "           4       0.92      0.81      0.86     18198\n",
            "\n",
            "    accuracy                           0.83    105000\n",
            "   macro avg       0.84      0.83      0.83    105000\n",
            "weighted avg       0.84      0.83      0.83    105000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}